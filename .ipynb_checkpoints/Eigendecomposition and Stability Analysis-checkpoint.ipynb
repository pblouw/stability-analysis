{
 "metadata": {
  "name": "",
  "signature": "sha256:e16d7eb9fc7d19256600b935865b1ad6e4064fc7bbd16df7f22d4ed0b665e3be"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Stability Analysis of a Constraint Parser\n",
      "This notebook describes how to analyze the behavior of a very simple constraint-based parser. The parser is implemented using a recurrently connected neural population, and functions to match inputs to complete parse trees that are encoded as HRRs. The parse trees are generated from a simple grammar of five context-free rewrite rules. Four trees in total are generated by the grammar. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Step 1: Define a Simple Grammar"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import scipy as sp\n",
      "import random\n",
      "import nengo\n",
      "import nengo.spa as spa\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# Define a set of context-free rewrite rules for a toy grammar\n",
      "rules = {\"S\":[[\"NP\",\"VP\"],[\"AUX\",\"NP\",\"VP\"]],\n",
      "         \"NP\":[[\"DET\",\"N\"]],\n",
      "         \"VP\":[[\"V\"],[\"V\",\"NP\"]]}\n",
      "\n",
      "# Generate terminating paths of the grammar as strings for an HRR parser\n",
      "def extend(path):\n",
      "    tip = path[-1]\n",
      "    if tip in rules:\n",
      "        expand = random.choice(rules[tip])\n",
      "        symbol = random.choice(expand)\n",
      "        if len(expand) < 2:\n",
      "            tag = 'M'\n",
      "        elif len(expand) > 2:\n",
      "            tag = ['L','M','R'][expand.index(symbol)]\n",
      "        else:\n",
      "            tag = ['L','R'][expand.index(symbol)]\n",
      "        return extend(path+[tag,'*',symbol])\n",
      "    else:\n",
      "        return ''.join(path)\n",
      "    \n",
      "def generate_paths(n=100, paths=[]):\n",
      "    if n==0:\n",
      "        return paths\n",
      "    else:\n",
      "        sample = extend(['S'])\n",
      "        if sample not in paths:\n",
      "            paths.append(sample)\n",
      "        return generate_paths(n-1, paths)\n",
      "\n",
      "all_paths = generate_paths()\n",
      "    \n",
      "# Group the paths for defining the constraints\n",
      "det_paths = [p for p in all_paths if 'DET' in p]\n",
      "aux_paths = [p for p in all_paths if 'AUX' in p]\n",
      "n_paths = [p for p in all_paths if p[-1] is 'N']\n",
      "v_paths = [p for p in all_paths if p[-1] is 'V']\n",
      "\n",
      "print det_paths\n",
      "print n_paths\n",
      "print v_paths\n",
      "print aux_paths"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['SL*NPL*DET', 'SR*VPR*NPL*DET', 'SM*NPL*DET']\n",
        "['SR*VPR*NPR*N', 'SM*NPR*N', 'SL*NPR*N']\n",
        "['SR*VPL*V', 'SR*VPM*V']\n",
        "['SL*AUX']\n"
       ]
      }
     ],
     "prompt_number": 299
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Step 2: Convert the Grammar into a set of Constraints between Terminating Paths\n",
      "\n",
      "These constraints are hand-coded from an examination of the trees the grammar generates, but ideally we should be able to convert any context-free grammar into a set of constraints of this sort. If the constraints are defined between individual constituents of a parse tree, this can be done using methods from Hale and Smolensky (2006). However, because we are using terminating paths, these methods cannot be applied here. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Change to order used for constraints (should fix generator wrt to this)\n",
      "det_paths = ['SL*NPL*DET','SM*NPL*DET','SR*VPR*NPL*DET']\n",
      "n_paths = ['SL*NPR*N','SM*NPR*N','SR*VPR*NPR*N']\n",
      "v_paths = ['SR*VPM*V','SR*VPL*V']\n",
      "aux_paths = ['SL*AUX']\n",
      "\n",
      "pos_constraints = [(det_paths[0],n_paths[0]),\n",
      "                   (det_paths[1],n_paths[1]),\n",
      "                   (det_paths[1],aux_paths[0]),\n",
      "                   (det_paths[2],n_paths[2]),\n",
      "                   (det_paths[2],v_paths[1]),\n",
      "                   (n_paths[1],aux_paths[0]),\n",
      "                   (n_paths[2],v_paths[1])]\n",
      "\n",
      "neg_constraints = [(det_paths[0],det_paths[1]),\n",
      "                   (det_paths[0],n_paths[1]),\n",
      "                   (det_paths[0],aux_paths[0]),\n",
      "                   (det_paths[1],n_paths[0]),\n",
      "                   (det_paths[2],v_paths[0]),\n",
      "                   (n_paths[0],n_paths[1]),\n",
      "                   (n_paths[0],aux_paths[0]),\n",
      "                   (n_paths[2],v_paths[0]),\n",
      "                   (v_paths[1],v_paths[0])]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 300
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Step 3: Generate a Transform Matrix that Encodes the Constraints\n",
      "\n",
      "Each constraint is implemented as a weighted sum the two outer products that can be formed from the pair of paths that the constraint is defined over. The weight is 1 if the constraint is positive, and -1 if the constraint is negative. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Initialize a SPA vocabulary for the path representations\n",
      "dimensions = 128\n",
      "\n",
      "vocab = spa.Vocabulary(dimensions, max_similarity=0.05)\n",
      "for path in all_paths:\n",
      "    vocab.parse(path)\n",
      "\n",
      "vocab = vocab.create_subset(all_paths)\n",
      "\n",
      "# Generate the recurrent transform matrix.\n",
      "# Note that the matrix is guaranteed to be symmetric. \n",
      "weights = np.zeros((dimensions,dimensions))\n",
      "\n",
      "for con in pos_constraints:\n",
      "    if con[1] != con[0]:\n",
      "        weights += np.outer(vocab[con[1]].v, vocab[con[0]].v)\n",
      "        weights += np.outer(vocab[con[0]].v, vocab[con[1]].v)\n",
      "for con in neg_constraints:\n",
      "    if con[1] != con[0]:\n",
      "        weights += -1*np.outer(vocab[con[1]].v, vocab[con[0]].v)\n",
      "        weights += -1*np.outer(vocab[con[0]].v, vocab[con[1]].v)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 301
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Step 4: Perform Stability Analysis on the Weight Matrix\n",
      "\n",
      "Note that the eigenvalue decomposition tends to generate extremely small numbers in place of eigenvalues of zero. As such, we ignore values with an absolute values of less than 0.001. The rank of an NxN matrix of is equal to the number of non-zero eigenvalues (since N-r is equal to dimensionality of the matrix's nullspace, which is comprised of eigenvectors with an eigenvalue of 0). To examine the behavior of a system defined by this weight matrix, we convert a hypothetical input into a linear combination of the eigenvectors of the matrix and then solve for the state of the system after an arbitrary amount of time by determining coefficents on the eigenvectors that give the system state at this time."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "eigvals, eigvecs = np.linalg.eig(weights)\n",
      "\n",
      "print 'Matrix Rank:'\n",
      "rank = np.linalg.matrix_rank(weights)\n",
      "print rank\n",
      "\n",
      "print ''\n",
      "print 'Eigenvalues:'\n",
      "for val in eigvals:\n",
      "    if abs(val.real) > 0.001:\n",
      "        print (val.real)\n",
      "        \n",
      "# Test the conversion of an input into a linear combination of eigenvectors\n",
      "sp_input = vocab['SL*AUX'] + vocab['SR*VPM*V']\n",
      "coefficients = np.linalg.solve(eigvecs, sp_input.v)\n",
      "\n",
      "# This should return 'Passed!' if the combination of eigenvectors is equal to the input\n",
      "print ''\n",
      "print 'Eigenbasis Test:'\n",
      "if np.allclose(np.dot(eigvecs,coefficients), sp_input.v) == True:\n",
      "    print 'Passed!'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Matrix Rank:\n",
        "9\n",
        "\n",
        "Eigenvalues:\n",
        "3.84896963128\n",
        "3.07661864406\n",
        "-1.35880721823\n",
        "-0.655313697964\n",
        "-0.819126697056\n",
        "-1.09833200423\n",
        "-1.01407142114\n",
        "-1.05892179859\n",
        "-0.947634026389\n",
        "\n",
        "Eigenbasis Test:\n",
        "Passed!\n"
       ]
      }
     ],
     "prompt_number": 302
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we want to see what the system does over time when given this input. With a matrix difference equation, we just multiply the input vector by the matrix to the power of t (time) to get the state of the system at that time."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "time = 2\n",
      "solution = np.dot(eigvecs, coefficients * eigvals**time)\n",
      "\n",
      "# Note that the eigvals > 1 cause the solution to blow up. \n",
      "# Norm of vector increases very rapidly. \n",
      "print ''\n",
      "print 'Norm of vector after '+str(time)+' time steps'\n",
      "print np.linalg.norm(solution)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Norm of vector after 2 time steps\n",
        "6.98551811471\n"
       ]
      }
     ],
     "prompt_number": 303
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can compare the coefficients on the eigenvectors between times. Essentially this tells us that the system moves toward a state dominated by the vectors with eigenvalues with abs val >= 1. We only look at the vectors whose weights change (i.e. the vectors whose eigenvalues are non-zero - the first nine)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'Change to weights on first 9 eigenvectors after computing solution:'\n",
      "for i in range(rank):\n",
      "    print 'Start: %f   End: %f' % (coefficients[i], coefficients[i]*eigvals[i]**time)\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Change to weights on first 9 eigenvectors after computing solution:\n",
        "Start: -0.292653   End: -4.335524\n",
        "Start: -0.554723   End: -5.250776\n",
        "Start: -0.681064   End: -1.257487\n",
        "Start: -0.529263   End: -0.227285\n",
        "Start: -0.380533   End: -0.255326\n",
        "Start: -0.426242   End: -0.514190\n",
        "Start: -0.393347   End: -0.404495\n",
        "Start: 0.417799   End: 0.468485\n",
        "Start: 0.323592   End: 0.290589\n"
       ]
      }
     ],
     "prompt_number": 304
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can also treat the weight matrix as encoding a differential equation. The form of the solution in this case changes slightly to include an exponential term. The systems behaves slightly differently in this case - the corresponding to the positive eigenvalues blowup, but the rest go to zero. We can perform a comparison between the two solutions by computing a normalized dot product. This comparison indicates that solutions are quite similar with respect to the direction in the space they point towards. Changing t indicates that the solutions converge as t grows."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print 'Solution assuming the matrix encodes a differential equation:'\n",
      "new_solution = np.dot(eigvecs, coefficients * np.exp(eigvals*time))\n",
      "\n",
      "print ''\n",
      "print 'Norm of vector after '+str(time)+' time steps'\n",
      "print np.linalg.norm(new_solution)\n",
      "\n",
      "print ''\n",
      "print 'Change to weights on first 9 eigenvectors after computing solution:'\n",
      "for i in range(rank):\n",
      "    print 'Start: %f   End: %f' % (coefficients[i], coefficients[i]*np.exp(eigvals[i]*time))\n",
      "\n",
      "print ''\n",
      "print 'Normalized dot product of the two solutions:'\n",
      "print np.dot(solution / np.linalg.norm(solution), new_solution / np.linalg.norm(new_solution)).real"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Solution assuming the matrix encodes a differential equation:\n",
        "\n",
        "Norm of vector after 2 time steps\n",
        "695.702740901\n",
        "\n",
        "Change to weights on first 9 eigenvectors after computing solution:\n",
        "Start: -0.292653   End: -644.948702\n",
        "Start: -0.554723   End: -260.851372\n",
        "Start: -0.681064   End: -0.044972\n",
        "Start: -0.529263   End: -0.142716\n",
        "Start: -0.380533   End: -0.073945\n",
        "Start: -0.426242   End: -0.047387\n",
        "Start: -0.393347   End: -0.051756\n",
        "Start: 0.417799   End: 0.050257\n",
        "Start: 0.323592   End: 0.048629\n",
        "\n",
        "Normalized dot product of the two solutions:\n",
        "0.857240146824\n"
       ]
      }
     ],
     "prompt_number": 305
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Step 5: Test Parsing Performance\n",
      "The preceding analysis indicates that any input to a parsing system using our constraint matrix should be modified in accordance with its representation as a linear combination of eigenvectors. The system should thus move towards a state that is biased to those SP's that share similar weights to the input on the eigenvectors that change the most over time. For example, if 'SLxNPLxDET' has a large weight on the first eigenvector, the solution state blows up this eigenvector, and any other SP that has a large weight on the first eigenvector will be proportionally more similar to the solution state than other SP's (e.g. an SP with a negative weight on the first eigenvector will be more dissimilar to the solution state). We can observe that SP's for terminating paths that have a postive constraint defined between them tend to have similar weights on these eigenvectors of interest (and vice versa for negative constraints)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Coefficient comparison for paths with varyings constraints between them\n",
      "DET_coeffs = np.linalg.solve(eigvecs, vocab['SL*NPL*DET'].v)\n",
      "N_coeffs = np.linalg.solve(eigvecs, vocab['SL*NPR*N'].v)\n",
      "AUX_coeffs = np.linalg.solve(eigvecs, vocab['SL*AUX'].v)\n",
      "\n",
      "print 'Comparison of weights on first 9 eigenvectors for a pair of positively constrained paths:'\n",
      "for i in range(rank):\n",
      "    print 'P1: %f   P2: %f' % (DET_coeffs[i], N_coeffs[i])\n",
      "   \n",
      "print ''\n",
      "print 'Comparison of weights on first 9 eigenvectors for a pair of negatively constrained paths:'\n",
      "for i in range(rank):\n",
      "    print 'P1: %f   P2: %f' % (DET_coeffs[i], AUX_coeffs[i])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Comparison of weights on first 9 eigenvectors for a pair of positively constrained paths:\n",
        "P1: 0.382011   P2: 0.424278\n",
        "P1: 0.063487   P2: 0.171682\n",
        "P1: -0.347589   P2: -0.497941\n",
        "P1: 0.154117   P2: -0.439330\n",
        "P1: 0.189275   P2: 0.052630\n",
        "P1: -0.698450   P2: 0.380126\n",
        "P1: 0.326707   P2: 0.283764\n",
        "P1: 0.273659   P2: -0.348903\n",
        "P1: -0.013504   P2: 0.006094\n",
        "\n",
        "Comparison of weights on first 9 eigenvectors for a pair of negatively constrained paths:\n",
        "P1: 0.382011   P2: -0.416396\n",
        "P1: 0.063487   P2: 0.003043\n",
        "P1: -0.347589   P2: -0.560347\n",
        "P1: 0.154117   P2: -0.289792\n",
        "P1: 0.189275   P2: 0.246629\n",
        "P1: -0.698450   P2: -0.027708\n",
        "P1: 0.326707   P2: -0.177318\n",
        "P1: 0.273659   P2: 0.467958\n",
        "P1: -0.013504   P2: 0.341493\n"
       ]
      }
     ],
     "prompt_number": 306
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we can try to parse inputs. We provide a partial tree as an input, and see which terminating paths are present in the state vector of the system after some specified time interval. Because the grammar we started with produces 4 trees, four unique tests are applied. In each test, a minimal number of paths from the tree are provided as input, and the resulting output is tested to see if it contains the entire tree. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Time to get solution at\n",
      "time = 1\n",
      "\n",
      "def normalize(v):\n",
      "    return v / np.linalg.norm(v)\n",
      "\n",
      "def get_parse(vocab, solution):\n",
      "    parse = []\n",
      "    for sp in vocab.keys:\n",
      "       if np.dot(vocab[sp].v, normalize(solution)).real > 0:\n",
      "            parse.append(sp)\n",
      "            print sp\n",
      "    return parse\n",
      "\n",
      "def test(prompt, condition):\n",
      "    coefficients = np.linalg.solve(eigvecs, prompt)\n",
      "    solution = np.dot(eigvecs, coefficients * np.exp(eigvals*time))\n",
      "    parse = get_parse(vocab, solution)\n",
      "    condition = condition.split('+')\n",
      "    if set(parse) == set(condition):\n",
      "        print 'Test Passed'\n",
      "        \n",
      "    else:\n",
      "        print 'Test Failed'\n",
      "    \n",
      "    \n",
      "# Test 1: Correct result is 'SL*NPL*DET+SL*NPR*N+SR*VPM*V'\n",
      "# We test by providing a path or two as input.\n",
      "# Try changing these to assess robustness.\n",
      "print 'TEST 1:'\n",
      "sp_input = vocab['SL*NPL*DET'].v + vocab['SR*VPM*V'].v\n",
      "test(sp_input, 'SL*NPL*DET+SL*NPR*N+SR*VPM*V')\n",
      "\n",
      "print ''\n",
      "print 'TEST 2:'\n",
      "# Test 2: Correct result is 'SL*NPL*DET+SL*NPR*N+SR*VPL*V+SR*VPR*NPL*DET+SR*VPR*NPR*N'\n",
      "sp_input = vocab['SL*NPR*N'].v + vocab['SR*VPL*V'].v\n",
      "test(sp_input, 'SL*NPL*DET+SL*NPR*N+SR*VPL*V+SR*VPR*NPL*DET+SR*VPR*NPR*N')     \n",
      "\n",
      "print ''\n",
      "print 'TEST 3:'\n",
      "# Test 4: Correct result is 'SL*AUX+SM*NPL*DET+SM*NPR*N+SR*VPM*V'\n",
      "sp_input = vocab['SM*NPL*DET'].v + vocab['SR*VPM*V'].v\n",
      "test(sp_input, 'SL*AUX+SM*NPL*DET+SM*NPR*N+SR*VPM*V')\n",
      "\n",
      "\n",
      "print ''\n",
      "print 'TEST 4:'\n",
      "# Test 2: Correct result is 'SL*AUX+SM*NPL*DET+SM*NPR*N+SR*VPL*V+SR*VPR*NPL*DET+SR*VPR*NPR*N'\n",
      "sp_input = vocab['SM*NPR*N'].v + vocab['SR*VPL*V'].v\n",
      "test(sp_input, 'SL*AUX+SM*NPL*DET+SM*NPR*N+SR*VPL*V+SR*VPR*NPL*DET+SR*VPR*NPR*N')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "TEST 1:\n",
        "SL*NPL*DET\n",
        "SR*VPM*V\n",
        "SL*NPR*N\n",
        "Test Passed\n",
        "\n",
        "TEST 2:\n",
        "SL*NPL*DET\n",
        "SR*VPL*V\n",
        "SR*VPR*NPR*N\n",
        "SR*VPR*NPL*DET\n",
        "SL*NPR*N\n",
        "Test Passed\n",
        "\n",
        "TEST 3:\n",
        "SR*VPM*V\n",
        "SL*AUX\n",
        "SM*NPR*N\n",
        "SM*NPL*DET\n",
        "Test Passed\n",
        "\n",
        "TEST 4:\n",
        "SR*VPL*V\n",
        "SR*VPR*NPR*N\n",
        "SR*VPR*NPL*DET\n",
        "SL*AUX\n",
        "SM*NPR*N\n",
        "SM*NPL*DET\n",
        "Test Passed\n"
       ]
      }
     ],
     "prompt_number": 307
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Overall, each input is mapped to an output that, when normalized, has a non-zero dot-product with only those vectors that belong in the parse of the input. This result seems to be consistent across different random initializations, but no robust testing has been performed yet. Future work will likely need to look at using more complex grammars that incorporate word representations rather than parts of speech.\n",
      "\n",
      "One puzzling issue has cropped up, though: longer processing times seem to produce worse results. This is peculiar given that the output ought to converge on the best parse of the input. "
     ]
    }
   ],
   "metadata": {}
  }
 ]
}